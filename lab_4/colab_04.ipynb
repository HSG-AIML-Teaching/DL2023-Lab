{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bkx4cUXoGgHw"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 900px\" src=\"banner.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0cP5Z789_rr"
   },
   "source": [
    "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"hsg_logo.png\">\n",
    "\n",
    "##  Bonus Lab 04 - Federated Learning (FL)\n",
    "\n",
    "Deep Learning, Fall Semester 2023, University of St. Gallen (HSG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rno8GqfC9_rz"
   },
   "source": [
    "In this lab, we will learn how to federate the training and evaluation of vanilla **Convolutional Neural Network (CNN)** learning. \n",
    "\n",
    "We will use the functionality of the [Flower](www.flower.dev) federated learning framework, to implement the federated learning setup. The different federated clients will collaboratively learn a model to classify the images of the CIFAR-10 dataset. More details on the `Flower` framework can be found via the following link https://flower.dev. Upon successful training, we will utilize the learned CNN model to classify so far unseen tiny images into distinct categories such as aeroplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. \n",
    "\n",
    "The figure below illustrates a high-level view on the machine learning process we aim to establish in this lab. This labs builds in large parts on the [An Introduction to Federated Learning](https://github.com/adap/flower/blob/main/doc/source/tutorial/Flower-1-Intro-to-FL-PyTorch.ipynb) notebook developed and published by the `Flower` development team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nswYOXvk9_r0"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 600px\" src=\"./federated_learning.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r93JK2DH9_r0"
   },
   "source": [
    "(Image of the CNN architecture created via http://alexlenail.me/)\n",
    "\n",
    "As always, pls. don't hesitate to ask all your questions either during the lab, post them in our CANVAS (StudyNet) forum (https://learning.unisg.ch), or send us an email (using the course email)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eW6dySzs9_r1"
   },
   "source": [
    "## 1. Lab Objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uzc9Xr69_r1"
   },
   "source": [
    "After today's lab, you should be able to:\n",
    "\n",
    "> 1. Understand the basic concepts, intuitions and major building blocks of **federated learning**.\n",
    "> 2. Know how to **implement federated clients** to enable model parameter sharing and aggregation.\n",
    "> 3. Understand how to **to train arbitrary models** in a federated setup collaboratively.\n",
    "> 4. Know how to **define federated learning strategies** and **run federated learning simulations**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPRKkkig9_r2"
   },
   "source": [
    "## 2. Setup of the Jupyter Notebook Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHYneRa6GgH7"
   },
   "source": [
    "The `Flower - A Friendly Federated Learning Framework` provides a unified approach to federated learning, analytics, and evaluation. It allows to federate a variety of any ML setups. Let's install the `Flower` framework by execution of the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNgQRE_8GgH7"
   },
   "outputs": [],
   "source": [
    "# !pip3 install -U flwr[\"simulation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note: You may want to restart the Colab runtime after the installation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore potential library warnings to not get distracted (don't try this at home :D ). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warning library\n",
    "import warnings\n",
    "\n",
    "# mute potential warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdiNpzmzGgH9"
   },
   "source": [
    "Import the federated learning libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0ln6vgrGgH9"
   },
   "outputs": [],
   "source": [
    "# import flower libraries\n",
    "import flwr as fl\n",
    "from flwr.common import Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iANa80_3GgH-"
   },
   "source": [
    "Determine the installed version of the Flower library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "scNyh_WkGgH-",
    "outputId": "90e70f88-81a7-4ed9-c018-2aa022f21410"
   },
   "outputs": [],
   "source": [
    "print('Available Flower library version:', fl.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mZL4i6W9_r2"
   },
   "source": [
    "Similar to the previous labs, we need to import a couple of Python libraries that allow for data analysis and data visualization. We will mostly use the `PyTorch`, `Numpy`, `Sklearn`, `Matplotlib`, `Seaborn` and a few utility libraries throughout this lab:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rykPqv60GgH_"
   },
   "source": [
    "Import Python utility libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9cwWtab9_r2"
   },
   "outputs": [],
   "source": [
    "# import utility python libraries\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06WkbaPWGgH_"
   },
   "source": [
    "Import Python data container libaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9_UHUhdGgIA"
   },
   "outputs": [],
   "source": [
    "# import data container libraries\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrB_51t89_r3"
   },
   "source": [
    "Import Python machine / deep learning libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZH6LhB_q9_r3"
   },
   "outputs": [],
   "source": [
    "# import the PyTorch deep learning library\n",
    "import torch, torchvision\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJJ5kfaf9_r4"
   },
   "source": [
    "Import Python plotting libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usAgsocK9_r4"
   },
   "outputs": [],
   "source": [
    "# import matplotlib, seaborn, and PIL data visualization libary\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZft6q1B9_r5"
   },
   "source": [
    "Enable notebook matplotlib inline plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXnX3zt_9_r5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-58e-iazJ8Aq"
   },
   "source": [
    "Create a structure of sub-directories to store the data as well as the trained neural network models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LtB6DCWjJ-gD"
   },
   "outputs": [],
   "source": [
    " # create data sub-directory inside the Colab Notebooks directory\n",
    "data_directory = './datasets/data_cifar10'\n",
    "if not os.path.exists(data_directory): os.makedirs(data_directory)\n",
    "\n",
    " # create models sub-directory inside the Colab Notebooks directory\n",
    "models_directory = './models/models_cifar10'\n",
    "if not os.path.exists(models_directory): os.makedirs(models_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcYgp4Gl9_r6"
   },
   "source": [
    "Set a random `seed` value to obtain reproducible results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdbqEjHb9_r7"
   },
   "outputs": [],
   "source": [
    "# init deterministic seed\n",
    "seed_value = 1234\n",
    "np.random.seed(seed_value) # set numpy seed\n",
    "torch.manual_seed(seed_value); # set pytorch seed CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable GPU computing (if available) by setting the `device` flag and init a `CUDA` seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cpu or gpu enabled device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type\n",
    "\n",
    "# init deterministic GPU seed\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "\n",
    "# log type of device enabled\n",
    "print('[LOG] Jupyter notebook with {} computation enabled'.format(str(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XH1CSkRV9_r8"
   },
   "source": [
    "## 3. Dataset Download and Data Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWDn7IQE9_r8"
   },
   "source": [
    "The **CIFAR-10 database** (**C**anadian **I**nstitute **F**or **A**dvanced **R**esearch) is a collection of images that are commonly used to train machine learning and computer vision algorithms. The database is widely used to conduct computer vision research using machine learning and deep learning methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awuRyFMd9_r8"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 500px; height: 500px\" src=\"./cifar10.png\">\n",
    "\n",
    "(Source: https://www.kaggle.com/c/cifar-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjdI5VVN9_r8"
   },
   "source": [
    "Further details on the dataset can be obtained via: *Krizhevsky, A., 2009. \"Learning Multiple Layers of Features from Tiny Images\",  \n",
    "( https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf ).\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaD13bmO9_r9"
   },
   "source": [
    "The CIFAR-10 database contains **60,000 color images** (50,000 training images and 10,000 validation images). The size of each image is 32 by 32 pixels. The collection of images encompasses 10 different classes that represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. Let's define the distinct classs for further analytics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1WlB2yXu9_r-"
   },
   "outputs": [],
   "source": [
    "cifar10_classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRslZNGV9_r-"
   },
   "source": [
    "Thereby the dataset contains 6,000 images for each of the ten classes. The CIFAR-10 is a straightforward dataset that can be used to teach a computer how to recognize objects in images.\n",
    "\n",
    "Let's download, transform and inspect the training images of the dataset. Therefore, we first will define the directory we aim to store the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2Bmhc-c9_r-"
   },
   "outputs": [],
   "source": [
    "train_path = data_directory + '/train_cifar10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6AGBP_K9_r_"
   },
   "source": [
    "Now, let's download the training data accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_-Zs4EU9_sA",
    "outputId": "32fd8e23-f2b6-4f8c-8594-574dbee4c9f5"
   },
   "outputs": [],
   "source": [
    "# define pytorch transformation into tensor format\n",
    "transf = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# download and transform training images\n",
    "cifar10_train_data = torchvision.datasets.CIFAR10(root=train_path, train=True, transform=transf, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g79sdHOw9_sA"
   },
   "source": [
    "Verify the volume of training images downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uiKFBLrI9_sA",
    "outputId": "2a666ecd-4399-4abc-fe5c-d7fc433af459"
   },
   "outputs": [],
   "source": [
    "# get the length of the training data\n",
    "len(cifar10_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWcoDhr_9_sC"
   },
   "source": [
    "Let's now decide on where we want to store the evaluation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKFBcveC9_sC"
   },
   "outputs": [],
   "source": [
    "eval_path = data_directory + '/eval_cifar10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nB5OpV4z9_sC"
   },
   "source": [
    "And download the evaluation data accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-OOVFFs9_sD",
    "outputId": "9a84eec4-5f45-429c-906a-1d1a5fd09044"
   },
   "outputs": [],
   "source": [
    "# define pytorch transformation into tensor format\n",
    "transf = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# download and transform validation images\n",
    "cifar10_eval_dataset = torchvision.datasets.CIFAR10(root=eval_path, train=False, transform=transf, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WF4VrcHG9_sD"
   },
   "source": [
    "Verify the volume of validation images downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vhZRDL4X9_sD",
    "outputId": "5c09e506-8545-4d33-e60b-ac99fe5c204c"
   },
   "outputs": [],
   "source": [
    "# get the length of the training data\n",
    "len(cifar10_eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-J2pz6mGgIP"
   },
   "source": [
    "In this lab, we simulate having a training dataset from **multiple organizations** (also called the 'cross-silo' setting in federated learning) by splitting the original CIFAR-10 dataset into **multiple partitions**. Each partition will represent the data from a single organization.  We're doing this purely for experimentation purposes, in the real world there's no need for data splitting because each organization already has their own data (so the data is naturally partitioned). Each **organization will act as a client** in the federated learning system. So having **4 organizations** participate in a federation means having 4 clients connected to the federated learning server. \n",
    "\n",
    "In a first step, we set the number of federated learning clients: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxSrB4zFGgIP"
   },
   "outputs": [],
   "source": [
    "num_clients = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPVNuBwBGgIP"
   },
   "source": [
    "Next, we partition the training set into 5 partitions of equal size to create the datasets of the individual clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RFVgoUtiGgIQ"
   },
   "outputs": [],
   "source": [
    "# define the partition size of each client dataset\n",
    "partition_size = len(cifar10_train_data) // num_clients\n",
    "\n",
    "# define the length of each partition\n",
    "lengths = [partition_size] * num_clients\n",
    "\n",
    "# create individual client dataset partitions\n",
    "cifar10_train_datasets = torch.utils.data.random_split(cifar10_train_data, lengths, torch.Generator().manual_seed(seed_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's briefly investigate the number of data samples per training partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cifar10_train_datasets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9Xivz3j9_sD"
   },
   "source": [
    "## 4. Federated Client Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Reatmz29_sD"
   },
   "source": [
    "In this section we, will implement the architecture of the **neural network** we aim to utilize to learn a model that is capable of classifying the 32x32 pixel CIFAR-10 images according to the objects contained in each image. However, before we start the implementation, let's briefly revisit the learning process we aim to establish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLOtA61_9_sE"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 900px\" src=\"process.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1qQOztA9_sE"
   },
   "source": [
    "The CNN, which we name `CIFAR10Net` and aim to implement consists of two **convolutional layers** and three **fully-connected layers**. In general, convolutional layers are specifically designed to learn a set of **high-level features** (\"patterns\") in the processed images, e.g., tiny edges and shapes. The fully-connected layers utilize the learned features to learn **non-linear feature combinations** that allow for highly accurate classification of the image content into the different image classes of the CIFAR-10 dataset, such as, birds, aeroplanes, horses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLZ0MWtL9_sE"
   },
   "source": [
    "Let's now implement the network architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XU-lZiqJ9_sF"
   },
   "outputs": [],
   "source": [
    "# implement the CIFAR10Net network architecture\n",
    "class CIFAR10Net(nn.Module):\n",
    "\n",
    "    # define the class constructor\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        # call super class constructor\n",
    "        super(CIFAR10Net, self).__init__()\n",
    "\n",
    "        # specify convolution layer 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0)\n",
    "\n",
    "        # define max-pooling layer 1\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # specify convolution layer 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "\n",
    "        # define max-pooling layer 2\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # specify fc layer 1 - in 16 * 5 * 5, out 120\n",
    "        self.linear1 = nn.Linear(16 * 5 * 5, 120, bias=True) # the linearity W*x+b\n",
    "        self.relu1 = nn.ReLU(inplace=True) # the non-linearity\n",
    "\n",
    "        # specify fc layer 2 - in 120, out 84\n",
    "        self.linear2 = nn.Linear(120, 84, bias=True) # the linearity W*x+b\n",
    "        self.relu2 = nn.ReLU(inplace=True) # the non-linarity\n",
    "\n",
    "        # specify fc layer 3 - in 84, out 10\n",
    "        self.linear3 = nn.Linear(84, 10) # the linearity W*x+b\n",
    "\n",
    "        # add a softmax to the last layer\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1) # the softmax\n",
    "\n",
    "    # define network forward pass\n",
    "    def forward(self, images: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        # high-level feature learning via convolutional layers\n",
    "\n",
    "        # define conv layer 1 forward pass\n",
    "        x = self.pool1(self.relu1(self.conv1(images)))\n",
    "\n",
    "        # define conv layer 2 forward pass\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "\n",
    "        # feature flattening\n",
    "\n",
    "        # reshape image pixels\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "\n",
    "        # combination of feature learning via non-linear layers\n",
    "\n",
    "        # define fc layer 1 forward pass\n",
    "        x = self.relu1(self.linear1(x))\n",
    "\n",
    "        # define fc layer 2 forward pass\n",
    "        x = self.relu2(self.linear2(x))\n",
    "\n",
    "        # define layer 3 forward pass\n",
    "        x = self.logsoftmax(self.linear3(x))\n",
    "\n",
    "        # return forward pass result\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcPpgIWI9_sK"
   },
   "source": [
    "Now, that we have implemented our `CIFAR10Net` we are ready to instantiate a network model to be trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGRVLvKS9_sK"
   },
   "outputs": [],
   "source": [
    "model = CIFAR10Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wofRVIpA9_sL"
   },
   "source": [
    "Once the model is initialized we can visualize the model structure and review the implemented network architecture by execution of the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XyE60fD9_sL",
    "outputId": "b6c63603-ee7b-422c-931c-9a5ab1ddd473"
   },
   "outputs": [],
   "source": [
    "# print the initialized architectures\n",
    "print('[LOG] CIFAR10Net architecture:\\n\\n{}\\n'.format(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wl5fE-TU9_sL"
   },
   "source": [
    "Looks like intended? Brilliant! Finally, let's have a look into the number of model parameters that we aim to train in the next steps of the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gkipagYv9_sL",
    "outputId": "a2fee1e0-49f6-4d91-85bf-1d85c595357c"
   },
   "outputs": [],
   "source": [
    "# init the number of model parameters\n",
    "num_params = 0\n",
    "\n",
    "# iterate over the distinct parameters\n",
    "for param in model.parameters():\n",
    "\n",
    "    # collect number of parameters\n",
    "    num_params += param.numel()\n",
    "    \n",
    "# print the number of model paramters\n",
    "print('[LOG] Number of to be trained CIFAR10Net model parameters: {}.'.format(num_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvqKcKUV9_sM"
   },
   "source": [
    "Ok, our `CIFAR10Net` model already encompasses an impressive number **62'006 model parameters** to be trained. Now that we have successfully implemented and defined the different CNN building blocks we will start federating the learning process in the following sections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWU9hWb_9_sO"
   },
   "source": [
    "## 5. Prepare Federated Client Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdQLICDt9_sO"
   },
   "source": [
    "In this section, we will start federating the process of `CIFAR10Net` model learning. Therefore, we will first prepare a **set of dataloaders** for the distinct federated clients. Second, we will implement a generic **model training** and **validation** routine to be utilized by the clients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Preparing the Training-, Validation-, and Test-Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a first step, we wrap the different data partitions by creating `PyTorch` dataloaders for each partition using a common batch size. We will use a **batch size of 32 samples**. Let's define the batch size of the dataloaders accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we instantiate a list of 4 training and 4 validation dataloaders (`trainloaders` and `valloaders`) representing the data of 4 different organizations. For each train data partition of in total 12,500 samples we will keep 10% for model validation purposes. Ultimately, each **trainloader-valloader pair contains 11,250 training examples and 1,250 validation examples**. We will also instantiate a single `testloader` (since we won't split the test set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KkyR0VsEGgIX"
   },
   "outputs": [],
   "source": [
    "# init client train- and valid-dataloaders\n",
    "trainloaders = []\n",
    "valloaders = []\n",
    "\n",
    "# iterate over dataset partitions\n",
    "for dataset in cifar10_train_datasets:\n",
    "    \n",
    "    # determine validation set samples\n",
    "    len_val = len(dataset) // num_clients  # 10 % validation set\n",
    "\n",
    "    # determine training set samples\n",
    "    len_train = len(dataset) - len_val\n",
    "\n",
    "    # compute random training and validation data split\n",
    "    ds_train, ds_val = torch.utils.data.random_split(dataset, [len_train, len_val], torch.Generator().manual_seed(42))\n",
    "\n",
    "    # init and collect client train dataloader\n",
    "    trainloaders.append(torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True))\n",
    "\n",
    "    # init and collect client validation dataloader\n",
    "    valloaders.append(torch.utils.data.DataLoader(ds_val, batch_size=batch_size))\n",
    "\n",
    "# init client test dataloader\n",
    "testloader = torch.utils.data.DataLoader(cifar10_eval_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note, this setup is only necessary for building research or educational systems, actual federated learning systems have their data naturally distributed across multiple partitions. Let's take a look at the **first batch of images and corresponding labels** in the first training set (i.e., `trainloaders[0]`) before we move on:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first batch of images and labels in the first training set (i.e., `trainloaders[0]`) before we move on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define image visualization function\n",
    "def imshow(img):\n",
    "    \n",
    "    # un-normalize image\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    \n",
    "    # transpose and show image\n",
    "    plt.imshow(np.transpose(img.numpy(), (1, 2, 0)))\n",
    "    \n",
    "    # plot image\n",
    "    plt.show()\n",
    "\n",
    "# retrieve random image batch of first dataloader\n",
    "images, labels = next(iter(trainloaders[0]))\n",
    "\n",
    "# create grid plot of image batch \n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# print labels of image batch\n",
    "print(' '.join('%5s' % cifar10_classes[labels[j]] for j in range(32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows a random batch of images from the first `trainloader` in our list of ten `trainloaders`. It also prints the labels associated with each image (i.e., one of the ten possible labels we've seen above). If you run the cell again, you should see another batch of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVM_dXkv9_sP"
   },
   "source": [
    "### 5.2 Preparing the Model Training and Validation Routines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgICsmcF9_sN"
   },
   "source": [
    "In a second step, we define the **training routine** that is supposed to be run by each federated client. \n",
    "\n",
    "We will use **Adam optimization** and set the **learning-rate to 0.001**. Each mini-batch step the optimizer will update the model parameters $\\theta$ values according to the degree of classification error determined by the **Negative Log-Likelihood (NLL)** loss. \n",
    "\n",
    "Let's set the training routine hyperparameters accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwFN6G8m9_sN"
   },
   "outputs": [],
   "source": [
    "# define learning rate and optimization strategy\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we proceed by implementing a general training routine for each of the federated clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define federated client training routine\n",
    "def train(model, loader, epochs: int):\n",
    "\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "\n",
    "    # init optimization criterion\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    \n",
    "    # push loss to compute device\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    # init model optimizer\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # set model in train mode\n",
    "    model.train()\n",
    "\n",
    "    # iterate over training epochs\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # init evaluation measures\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "\n",
    "        # iterate over data loader batches\n",
    "        for images, labels in loader:\n",
    "\n",
    "            # push images and labels to compute device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # reset optimizer gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # run forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # compute loss\n",
    "            loss = criterion(model(images), labels)\n",
    "\n",
    "            # run backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # update model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # collect batch loss\n",
    "            epoch_loss += loss\n",
    "\n",
    "            # collect batch samples\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # collect correctly classified instances\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss /= len(loader.dataset)\n",
    "\n",
    "        # compute epoch accuracy\n",
    "        epoch_accuracy = correct / total\n",
    "\n",
    "        # print training metrics\n",
    "        now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "        print('[LOG {}] epoch: {} train-loss: {} accuracy: {}'.format(str(now), str(epoch+1), str(round(epoch_loss.item(), 6)), str(round(epoch_accuracy, 4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sL8GzqrqGgIW"
   },
   "source": [
    "### 5.3 Preparing the Model Validation Routine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a third step, we define the **validation routine** that is supposed to be run by each federated client. \n",
    "\n",
    "We will again use the **Negative Log-Likelihood (NLL)** loss to determine the classification error of a respective client model. In addition, we also compute the **classification accuracy** of the model in terms of the fraction of correctly classified images. \n",
    "\n",
    "Next, let's continue and implement the different steps of the validation routine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NvUgiI_IGgIX"
   },
   "outputs": [],
   "source": [
    "# define federated client validation routine\n",
    "def validate(model, loader):\n",
    "    \n",
    "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
    "    \n",
    "    # define optimization criterion\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # push loss to compute device\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    # init evaluation metrics\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    \n",
    "    # set network in eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    # disable gradient computation\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # iterate over data loader batches\n",
    "        for images, labels in loader:\n",
    "            \n",
    "            # push images and labels to compute device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # run model forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # compute optimization criterion\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            \n",
    "            # determine class predictions\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # determine total number of samples\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            # determine total number of correct classifcations\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # compute evaluation loss\n",
    "    loss /= len(loader.dataset)\n",
    "    \n",
    "    # compute evaluation accuracy\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    # return evaluation metrics\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XynE4DPGgIY"
   },
   "source": [
    "Finally, we have **implemented all the basic building blocks** we required: a dataset, a model, a training function, and a test function. \n",
    "\n",
    "Let's put them together to train the model on the dataset of one organization (`trainloaders[0]`). This simulates the reality of most machine learning projects today: each organization has their own data and trains models only on this internal data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run our evaluation for **2 federated rounds** of communication. In each round, the client will train the model for **5 training epochs**. Therefore, we set the following hyperparameters for the evaluation run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of fl rounds and epochs per round\n",
    "flrounds = 2\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now proceed and run the simulation for a single organization using the hyperparameter set above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "fHa0_D4UGgIY",
    "outputId": "07628440-81dc-4864-fbe8-86d1311cb734"
   },
   "outputs": [],
   "source": [
    "# get the first train dataloader\n",
    "trainloader = trainloaders[0]\n",
    "\n",
    "# get the first validation dataloader\n",
    "valloader = valloaders[0]\n",
    "\n",
    "# instantiate model and push compute device\n",
    "model = CIFAR10Net().to(device)\n",
    "\n",
    "# iterate over federated rounds\n",
    "for flround in range(flrounds):\n",
    "\n",
    "    # train model\n",
    "    train(model, trainloader, epochs)\n",
    "\n",
    "    # validate model\n",
    "    valid_loss, valid_accuracy = validate(model, valloader)\n",
    "\n",
    "    # print validation metrics\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "    print('[LOG {}] valid-loss: {} accuracy: {}'.format(str(now), str(round(valid_loss, 6)), str(round(valid_accuracy, 4))))\n",
    "\n",
    "# test model\n",
    "test_loss, test_accuracy = validate(model, testloader)\n",
    "\n",
    "# print final test metrics\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG {}] final test-loss: {} accuracy: {}'.format(str(now), str(round(test_loss, 6)), str(round(test_accuracy, 4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the simple CNN on our **CIFAR-10 split for 2 rounds and 5 epochs** should result in a test set accuracy of **about 50%**, which is not great, but at the same time, it doesn't really matter for the purposes of this lab. The intent was just to show a simplistic centralized training pipeline that sets the stage **federated learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82Abs6o4GgIY"
   },
   "source": [
    "## 6. Setup Federated Learning Clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook cells above demonstrated a simple centralized training workflow. Next, we'll prepare a simulation where we have multiple datasets in multiple organizations. Finally, we will train a model over these organizations using federated learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Get and Set the Client Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In federated learning, the server sends the global model parameters to the client, and the client updates the local model with the parameters received from the server. It then trains the model on the local data (which changes the model parameters locally) and sends the updated/changed model parameters back to the server (or, alternatively, it sends just the gradients back to the server, not the full model parameters).\n",
    "\n",
    "To establish such a setup in the `Flower` library, we need to implement **two helper functions**. This to **update the local model with parameters received from the server** and to **get the updated model parameters from the local model**. The following two functions do just that for the `PyTorch` model above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BRimojzTGgIY"
   },
   "outputs": [],
   "source": [
    "# define the set parameter function -> update local model parameters\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    \n",
    "    # determine parameters dictionary\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    \n",
    "    # convert to torch tensors to ordered dict\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    \n",
    "    # load parameters into model\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "# define the get parameter function -> get local model parameters\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    \n",
    "    # determine the model parameters as list of numpy arrays\n",
    "    parameters = [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "    \n",
    "    # return the model parameters\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The details of how both functions work are not really important here (feel free to consult the PyTorch documentation if you want to learn more). In essence, we use `state_dict` to access PyTorch model parameter tensors. The parameter tensors are then converted to/from a list of NumPy ndarray's (which Flower knows how to serialize/deserialize)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Implement Federated Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFZNc_ALGgIZ"
   },
   "source": [
    "With that out of the way, let's move on to the interesting part. Federated learning systems consist of a server and multiple clients. In `Flower`, clients can be created by using the subclass`flwr.client.NumPyClient`. We will use this subclass in this tutorial since it is straightforward to implement. To implement the Flower client, we create a subclass of `flwr.client.NumPyClient` and implement the three methods (i) `get_parameters`, (ii) `fit`, and (iii) `evaluate`. \n",
    "\n",
    "> * The `get_parameters` method returns the current local model parameters. \n",
    "> * The `fit` method receives model parameters from the server, train the model parameters on the local data, and return the (updated) model parameters to the server. \n",
    "> * The `evaluate` method receives model parameters from the server, evaluate the model parameters on the local data, and return the evaluation result to the server.\n",
    "\n",
    "Next, let's accomplish a simple `Flower` client implementation that brings everything together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tPlxIET_GgIZ"
   },
   "outputs": [],
   "source": [
    "# define federated client\n",
    "class FederatedClient(fl.client.NumPyClient):\n",
    "\n",
    "    # init the federated client\n",
    "    def __init__(self, net, trainloader, valloader):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    # define get parameters function\n",
    "    def get_parameters(self, config):\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    # define model training function\n",
    "    def fit(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=epochs)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    # define model evaluation function\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = validate(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FlowerClient` client defines how local training/evaluation will be performed and allows `Flowe` to call the local training/evaluation through `fit` and `evaluate`. Each instance of `FlowerClient` represents a *single client* in our federated learning system. \n",
    "\n",
    "Federated learning systems have multiple clients (otherwise there's not much to federate), so each client will be represented by its own instance of `FlowerClient`. If we have, for example, three clients in our workload, then we'd have three instances of `FlowerClient`. Flower calls `FlowerClient.fit` on the respective instance when the server selects a particular client for training (and `FlowerClient.evaluate` for evaluation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Instantiate Federated Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enable the `Flower` libray to dynamically create clients when necessary, we need to implement a function called `client_fn` that creates a `FlowerClient` instance on demand. Flower calls `client_fn` whenever it needs an instance of one particular client to call `fit` or `evaluate` (those instances are usually discarded after use, so they should not keep any local state). Clients are identified by a client ID, or short `cid`. The `cid` can be used, for example, to load different local data partitions for different clients, as can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JNAsKmp7GgIa"
   },
   "outputs": [],
   "source": [
    "def client_fn(cid: str) -> FederatedClient:\n",
    "\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    # instantiate client model\n",
    "    model = CIFAR10Net()\n",
    "\n",
    "    # push client model to compute device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # init the client train dataloader\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    \n",
    "    # init the client eval dataloader\n",
    "    valloader = valloaders[int(cid)]\n",
    "    \n",
    "    # note: each client gets a different trainloader/valloader, so each client\n",
    "    # will train and evaluate on their own unique data\n",
    "    \n",
    "    # instantiate a single federated client representing a single organization\n",
    "    return FederatedClient(model, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the class `FlowerClient` which defines client-side training/evaluation and `client_fn` which allows Flower to create `FlowerClient` instances whenever it needs to call `fit` or `evaluate` on one particular client.\n",
    "\n",
    "In this lab, we want to simulate a federated learning system with **4 clients on a single machine**. This means that the server and all 4 clients will live on a single machine and share resources such as CPU, GPU, and memory. Having 4 clients would mean having 4 instances of `FlowerClient` in memory. \n",
    "\n",
    "Please note, doing such simulations on a single machine can quickly exhaust the available memory resources, even if only a subset of these clients participates in a single round of federated learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Setup and Run Federated Learning Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we will define a federated evaluation metric and federated learning strategy. Afterwards, we will run our first federated learning simulation using the `Flower`framework. Finally, we will investigate and visualize the obtained results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Define Federated Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `Flower` framework we need to define evaluation metrics and how to handle/aggregate these metrics. Let's create a simple weighted averaging function to aggregate the classification `accuracy` metric we return from each federated client via its respective `evaluate` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BB76ffyaMnxt"
   },
   "outputs": [],
   "source": [
    "# define weighted average of client's classification accuracy\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    \n",
    "    \"\"\"Compute the weighted average accuracy over all federated clients.\"\"\"\n",
    "\n",
    "    # determine client accuracies\n",
    "    accuracies = [m[\"accuracy\"] for _, m in metrics]\n",
    "\n",
    "    # multiply accuracy of each client by number of examples used\n",
    "    numerator = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    denominator = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # compute average weighted classification accuracy\n",
    "    accuracy = round(sum(numerator) / sum(denominator), 4)\n",
    "\n",
    "    # print validation metrics\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "    print('[LOG {}] weighted average accuracy: {}'.format(str(now), str(round(accuracy, 4))))\n",
    "    \n",
    "    # aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": accuracy, \"accuracies\": accuracies}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Define Federated Learning Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flower has a number of built-in strategies, but we can also use our own strategy implementations to customize nearly all aspects of the federated learning approach. For this example, we use the built-in **Federated Averaging (*FedAvg*) strategy** implementation and customize it using a few hyperparameters. \n",
    "\n",
    "We set the following hyperparameters of the strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of clients used during training\n",
    "fraction_fit=1.0  # Sample 100% of available clients for training\n",
    "\n",
    "# fraction of clients used during validation \n",
    "fraction_evaluate=1.0  # Sample 100% of available clients for evaluation\n",
    "\n",
    "# minimum number of clients used during training\n",
    "min_fit_clients=num_clients // 2  # never sample less than 2 clients for training \n",
    "\n",
    "# minimum number of clients used during validation\n",
    "min_evaluate_clients=num_clients // 2  # never sample less than 2 clients for evaluation\n",
    "\n",
    "# minimum number of total clients in the system\n",
    "min_available_clients=num_clients  # never run with less than 4 available clientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we also tell the strategy how to handle/aggregate custom evaluation metrics, and we do so by passing metric aggregation functions to the strategy. The strategy will then call these functions whenever it receives fit or evaluate metrics from clients. To compute the **weighted average classification error** upon each training round we set the `evaluate_metrics_aggregation_fn` parameter accordingly. \n",
    "\n",
    "Let's now parametrize and init the *FedAvg* strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zGx_MjGfGgIa"
   },
   "outputs": [],
   "source": [
    "# init FedAvg learning strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=fraction_fit,\n",
    "        fraction_evaluate=fraction_evaluate,\n",
    "        min_fit_clients=min_fit_clients,\n",
    "        min_evaluate_clients=min_evaluate_clients,\n",
    "        min_available_clients=num_clients,\n",
    "        evaluate_metrics_aggregation_fn=weighted_average,  # use predefined metrics aggregation function\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Run Federated Learning Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are able to run an actual federated learning simulation using `flwr.simulation.start_simulation`. To start the simulation we run the `start_simulation` method which - you guessed it - starts the simulation. \n",
    "\n",
    "But how will this work? How does the `Flower` library execute this simulation?\n",
    "\n",
    "When we call `start_simulation`, we tell the `Flower` library that there are 4 clients (`num_clients = 4`). Flower then goes ahead an asks the `FedAvg` strategy to select clients. `FedAvg` knows that it should select 100% of the available clients (`fraction_fit=1.0`), so it goes ahead and selects 4 random clients (i.e., 100% of 4).\n",
    "\n",
    "Next, the `Flower` libray asks the selected 4 clients to train the model. When the server receives the model parameter updates from the clients, it hands those updates over to the strategy (*FedAvg*) for aggregation. The strategy aggregates those updates and returns the new global model, which then gets used in the next round of federated learning. Let's now start the simulation accordingly:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before start the simulation we set the number of **federated training rounds** we aim to simulate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of fl rounds\n",
    "flrounds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now proceed and start the simulation accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "id": "4hASllurGgIa",
    "outputId": "9376c26d-d2cb-48a3-cacb-9b700020c084"
   },
   "outputs": [],
   "source": [
    "# start federated learning simulation\n",
    "simulation_results = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=num_clients,\n",
    "    config=fl.server.ServerConfig(num_rounds=flrounds),\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations, you just trained a convolutional neural network, federated over 4 clients!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's, as a final step, also visualize the central weighted averaged learning progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare plot\n",
    "plt.rcParams['figure.figsize'] = [12, 4]\n",
    "fig, ax = plt.subplots(ncols=2, nrows=1)\n",
    "\n",
    "# add grid\n",
    "ax[0].grid(linestyle='dotted')\n",
    "ax[1].grid(linestyle='dotted')\n",
    "\n",
    "# determine train epochs and losses\n",
    "train_rounds = [ele[0] for ele in simulation_results.losses_distributed]\n",
    "train_round_losses = [ele[1] for ele in simulation_results.losses_distributed]\n",
    "train_round_accuracies = [ele[1] for ele in simulation_results.metrics_distributed['accuracy']]\n",
    "\n",
    "# plot the training epochs vs. the epochs' classification error\n",
    "ax[0].plot(train_rounds, train_round_losses, color='limegreen')\n",
    "ax[1].plot(train_rounds, train_round_accuracies, color='darkorange')\n",
    "\n",
    "# add axis legends\n",
    "ax[0].set_xlabel('[communication round $r_i$]', fontsize=10)\n",
    "ax[0].set_ylabel('[weighted average loss $\\mathcal{L}^{NLL}$]', fontsize=10)\n",
    "ax[1].set_xlabel('[communication round $r_i$]', fontsize=10)\n",
    "ax[1].set_ylabel('[weighted prediction accuracy]', fontsize=10)\n",
    "\n",
    "# add plot title\n",
    "ax[0].set_title('FL Communication Rounds $r_i$ vs. Weighted Average Loss $L^{NLL}$', fontsize=10)\n",
    "ax[1].set_title('FL Communication Rounds $r_i$ vs. Weighted Prediction Accuracy', fontsize=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as the local individual federated client learning progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare plot\n",
    "plt.rcParams['figure.figsize'] = [12, 4]\n",
    "fig, ax = plt.subplots(ncols=2, nrows=2)\n",
    "\n",
    "# set subplot spacing\n",
    "fig.subplots_adjust(hspace=.6)\n",
    "\n",
    "# client count\n",
    "client = 0\n",
    "\n",
    "# iterate over distinct clients\n",
    "for i in range(0, 2):\n",
    "    \n",
    "    # iterate over distinct clients\n",
    "    for k in range(0, 2):\n",
    "        \n",
    "        # add grid\n",
    "        ax[i, k].grid(linestyle='dotted')\n",
    "\n",
    "        # determine train epochs and losses\n",
    "        train_rounds = [ele[0] for ele in simulation_results.losses_distributed]\n",
    "        train_round_accuracies = [ele[1][client] for ele in simulation_results.metrics_distributed['accuracies']]\n",
    "\n",
    "        # plot the training epochs vs. the epochs' classification error\n",
    "        ax[i, k].plot(train_rounds, train_round_accuracies, color='darkorange')\n",
    "\n",
    "        # add axis legends\n",
    "        ax[i, k].set_xlabel('[round $r_i$]', fontsize=10)\n",
    "        ax[i, k].set_ylabel('[accuracy]', fontsize=10)\n",
    "        \n",
    "        # add plot title\n",
    "        ax[i, k].set_title('FL Client {} - Prediction Accuracy'.format(str(client)), fontsize=10)\n",
    "        \n",
    "        # increase client count\n",
    "        client += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, you understand the basics of federated learning using the `Flower` federated learning framework. The same approach you've seen can be used with other machine learning frameworks (not just PyTorch) and tasks (not just CIFAR-10 images classification), for example NLP with Hugging Face Transformers or speech with SpeechBrain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Lab Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, a step by step introduction into **design, implementation, training and evaluation** of a federated learning workflow is presented. The code presented in this lab may serves as a starting point for developing more complex, more detailed or more tailored federated learning workflows. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "254.39999389648438px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

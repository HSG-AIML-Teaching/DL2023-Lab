{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style='max-width: 1000px' src=\"images/banner.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" style='max-width: 150px; height: auto' src=\"images/hsg_logo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 03 - \"Hypernetworks\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mzz0qB7dyo42"
   },
   "source": [
    "## Objective\n",
    "\n",
    "After learning the concepts in this lab, you should be able to:\n",
    "\n",
    "- Understand the basic tools and methods needed for the implementation of Hypernetworks \n",
    "- Implement basic Hypernetworks\n",
    "- Apply two different types of slicing techniques to reduce the size of the Hypernetwork\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "\n",
    "1. **A Simple Hypernetwork**: How Hypernetworks can be implemented in PyTorch.\n",
    "2. **Slicing Technique 1**: A slicing technique that treats all parameters as a single vector.\n",
    "2. **Slicing Technique 2**: A layer-wise slicing technique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img align='center' style='max-width: 700px' src='images/hypernet_forward.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Animation: The forward and backward propagation steps of a Hypernetwork. First, the Hypernetwork (the blue network) generates the weights of the main model (the white network) using some context information $t$. Then, it makes prediction on input $x$ using generated weights $w$ in a stateless manner. Finally, in the backpropagation step, the gradiants of the Hypernetwork are obtained by backpropagating through the main model to the Hypernetwork.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>1. A Simple Hypernetwork</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we implement a simple hypernetwork that generates the weights of an MLP. The weights are generated as a single vector of weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's start with the definition of the MLP model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_inp, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(n_inp, n_hidden)\n",
    "        self.linear_2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.linear_3 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.classifier = nn.Linear(n_hidden, n_out)\n",
    "        \n",
    "        self.activ = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.activ(self.linear_1(x))\n",
    "        x = self.activ(self.linear_2(x)) \n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, we initialize an instance of the model, and feed it with some input to get the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 5])\n"
     ]
    }
   ],
   "source": [
    "main_model = MLP(10, 50, 5)\n",
    "x = torch.randn(32, 10)\n",
    "out = main_model(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example, the weights of the model are stored inside the model. Therefore, when we call `main_model(x)`, it uses the weights stored in the model's `state_dict` to do the forward propagation. What if the weights are provided from outside the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's first generate the weights of the model with another neural network called the Hypernetwork:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Hypernetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate the weights of anotehr model, we first need to know the number of parameters in the main model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  5905\n"
     ]
    }
   ],
   "source": [
    "# Shape of each parameter as a dictionary of name: shape\n",
    "param_shapes = {n: p.shape for (n, p) in main_model.named_parameters()}\n",
    "\n",
    "# Total number of parameters in the model\n",
    "num_params = sum([p.numel() for p in main_model.parameters()])\n",
    "print(\"Number of parameters: \", num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to define the architecture of the Hypernetwork. The Hypernetwork is also an MLP that maps the input to the vector space of the main model's weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic version of a Hypernetwork treats all weights as a single vector as shown in the following animation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align='center' style='max-width: 700px' src='images/no_slice.gif'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hypernetwork(nn.Module):\n",
    "    def __init__(self, n_inp, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(n_inp, n_hidden)\n",
    "        self.linear_2 = nn.Linear(n_hidden, n_out)\n",
    "\n",
    "        self.actv = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.actv(self.linear_1(x))\n",
    "        x = self.linear_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypernetwork = Hypernetwork(10, 20, num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to the hypernetwork is a 10-dimensional tensor, which is then mapped to a to 20-dimenstional hidden state. In the final linear layer, the hidden state is mapped to the vector space of the main model's weights. Let's forward a random tensor to the  Hypernetwork:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypernetwork output size:  torch.Size([1, 5905])\n"
     ]
    }
   ],
   "source": [
    "hn_out = hypernetwork(torch.randn(1, 10))\n",
    "print(\"Hypernetwork output size: \", hn_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output size is equal to the number of parameters in the main model. Now, we need to reshape this tensor back to the original tensor shapes of the main model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reshape the output of the hypernetwork, we can start from the index zero of the Hypernetwork's output tensor, and slice it according to the original number of parameters in each layer of the main model. In the end, we need to reshape the tensor to the original size. We can store the reshaped results in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the reshaped parameters\n",
    "reshaped_params = {}\n",
    "\n",
    "# Start with an offset of 0\n",
    "offset = 0\n",
    "for (n, p) in param_shapes.items():\n",
    "    sliced_parameter = hn_out[0][offset:offset+p.numel()]\n",
    "    reshaped_params[n] = sliced_parameter.view(p)\n",
    "    offset += p.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the shape of reshaped parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_1.weight torch.Size([50, 10])\n",
      "linear_1.bias torch.Size([50])\n",
      "linear_2.weight torch.Size([50, 50])\n",
      "linear_2.bias torch.Size([50])\n",
      "linear_3.weight torch.Size([50, 50])\n",
      "linear_3.bias torch.Size([50])\n",
      "classifier.weight torch.Size([5, 50])\n",
      "classifier.bias torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "for n, p in reshaped_params.items():\n",
    "    print(n, p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Forwarding with Parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, an important question to answer is: how to use these generated weights to make prediction with the main model? \n",
    "\n",
    "<font color='darkgreen'>[Q] Can we just copy these weights to the `state_dict` dictionary of the model?</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we have two ways to forward input with parameters:\n",
    "\n",
    "1. Defining the function `forward_with_parameters()`\n",
    "2. Calling the main model ina stateless way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: Defining a new forward function that accepts external parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add a new forward function that receivs both $x$ and $w$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same model with a different forward function\n",
    "class ModelV2(nn.Module):\n",
    "    def __init__(self, n_inp, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        # ! These layers are not used during the forward pass\n",
    "        self.linear_1 = nn.Linear(n_inp, n_hidden)\n",
    "        self.linear_2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.linear_3 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.classifier = nn.Linear(n_hidden, n_out)\n",
    "        \n",
    "        self.activ = nn.ReLU()\n",
    "    \n",
    "    def forward_with_params(self, x, params):\n",
    "        # Params is a dictionary of name: tensor\n",
    "        x = F.linear(x, params[\"linear_1.weight\"], params[\"linear_1.bias\"])\n",
    "        x = F.relu(x) \n",
    "        x = F.linear(x, params[\"linear_2.weight\"], params[\"linear_2.bias\"])\n",
    "        x = F.relu(x)\n",
    "        x = F.linear(x, params[\"linear_3.weight\"], params[\"linear_3.bias\"])\n",
    "        x = F.relu(x)\n",
    "        x = F.linear(x, params[\"classifier.weight\"], params[\"classifier.bias\"])\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='darkgreen'> [Q] Why are the opeations inside the new forward function performed as functionals instead of using the layers?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create an instance of the model with the forward-with-parameter pass, and feed it with the same random tensor used to  generate the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "model = ModelV2(10, 20, 5)\n",
    "out = model.forward_with_params(torch.randn(1, 10), reshaped_params)\n",
    "\n",
    "# Print the output shape\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: Stateless call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make stateless calls from a stateful model, we can the use following function from PyTorch (available since version 2.0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.stateless import functional_call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can directly use the main model without adding a new forward function. The only thing we need to do is to call it as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "out = functional_call(main_model, reshaped_params, torch.randn(1, 10))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's that simple! So far, we have learned to use an external model called the Hypernetwork to generate th weights a main model and make prediction with the generated weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='darkred'>**BUT**, there is a big problem!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of parameters in the hypernetwork can easily \"explode\" this way. The Hypernetwork employs a linear layer in its final layer to map the hidden state of the Hypernetwork to the vectors space of the main model's weights. This essentially means that, if the size of the hidden state is $S$, and the total number of parameters is $N$, the total number of parameters in the hypernetwork will be $N \\times S$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in main model:  5905\n",
      "Number of parameters in hypernetwork:  124225\n",
      "Ratio:  21.037256562235395\n"
     ]
    }
   ],
   "source": [
    "n_params_main_model = sum([p.numel() for p in main_model.parameters()])\n",
    "n_params_hypernetwork = sum([p.numel() for p in hypernetwork.parameters()])\n",
    "\n",
    "print(\"Number of parameters in main model: \", n_params_main_model)\n",
    "print(\"Number of parameters in hypernetwork: \", n_params_hypernetwork)\n",
    "\n",
    "# Ratio of parameters in hypernetwork to main model\n",
    "print(\"Ratio: \", n_params_hypernetwork / n_params_main_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is super inefficient. The number of parameters in the Hypernetwork is ~21 times more than the number of parameters in the main model. We need to find better ways to generate the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>2. Slicing Technique 1</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we design a specific slicing technique that splits the entire network parameters with $N$ parameters into $K$ chunks, where $N \\mod K = 0$.\n",
    "\n",
    "The Hypernetwork then generates the weight of each chunk separately, conditioned on the chunk ID:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align='center' style='max-width: 700px' src='images/slice_1.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we want to implement an MLP to train an MNIST classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_inp, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(n_inp, n_hidden)\n",
    "        self.linear_2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.linear_3 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.classifier = nn.Linear(n_hidden, n_out)\n",
    "\n",
    "        self.activ = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.activ(self.linear_1(x))\n",
    "        x = self.activ(self.linear_2(x))\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward_with_params(self, x, params):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.linear(x, params[\"linear_1.weight\"], params[\"linear_1.bias\"])\n",
    "        x = F.relu(x)\n",
    "        x = F.linear(x, params[\"linear_2.weight\"], params[\"linear_2.bias\"])\n",
    "        x = F.relu(x)\n",
    "        x = F.linear(x, params[\"linear_3.weight\"], params[\"linear_3.bias\"])\n",
    "        x = F.relu(x)\n",
    "        x = F.linear(x, params[\"classifier.weight\"], params[\"classifier.bias\"])\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the previous example, we need to implement a Hypernetwork that generats the weights of this MLP. The important point here is to slice the weights in the output as explained above.\n",
    "\n",
    "In order to avoid \"parameter explosion\" in the Hypernetwork, we need to use a single linear mapping from the hidden state of the Hypernetwork to each chunk of the main model's weight. Using the same mapping, requires conditioning the mapping on the chunk ID. Therefore, we define an **embedding layer** that maps chunk ID to a vector which is then concatenated to the hidden state of the Hypernetwork:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hypernetwork(nn.Module):\n",
    "    def __init__(self, n_inp, n_hidden, n_out, chunk_size, dim_emb):\n",
    "        super().__init__()\n",
    "        # Embedding layer for each state\n",
    "        self.n_chunks = n_out // chunk_size\n",
    "        self.emb = nn.Embedding(self.n_chunks, dim_emb)\n",
    "\n",
    "        # Initialize emb weights with uniform distribution\n",
    "        nn.init.uniform_(self.emb.weight, -1.0, 1.0)\n",
    "\n",
    "        # Hypernetwork's layers\n",
    "        self.linear_1 = nn.Linear(n_inp, n_hidden)\n",
    "        self.linear_2 = nn.Linear(n_hidden + dim_emb, chunk_size)\n",
    "        \n",
    "        # Activation function\n",
    "        self.actv = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Retrieve embedding for all layers\n",
    "        emb_inp = torch.arange(self.n_chunks).to(x.device)\n",
    "        emb = self.emb(emb_inp)\n",
    "\n",
    "        # Flatten x and apply the first linear layer\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.actv(self.linear_1(x))\n",
    "\n",
    "        # Unsqueeze x in the second dimension and replicate it for n times\n",
    "        x = x.unsqueeze(1).repeat(1, self.n_chunks, 1)\n",
    "\n",
    "        # Unsqueeze emb in the first dimension and replicate it for n times\n",
    "        emb = emb.unsqueeze(0).repeat(x.shape[0], 1, 1)\n",
    "\n",
    "        # Concatenate x and emb along the last dimension\n",
    "        x = torch.cat([x, emb], dim=-1)\n",
    "\n",
    "        # Apply the second linear layer on the conditioned x\n",
    "        x = self.linear_2(x)\n",
    "\n",
    "        # Flatten the output and return it\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The next question to answer is: what is a good chunk size?**\n",
    "\n",
    "Since the number of parameters in the main model can vary, we define a function that takes the number of parameters $N$ , and returns the biggest divisor of $N$ that is smaller than $\\sqrt{N}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biggest_divisor(n):\n",
    "    # Find the biggest divisor of n that is smaller than the square root of n\n",
    "    for i in range(int(n**0.5), 0, -1):\n",
    "        if n % i == 0:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, the `biggest_divisor` function finds the chunks size for us.\n",
    "\n",
    "Now, we need to define an instance of the main model and its corresponding Hypernetwork:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size: 20\n"
     ]
    }
   ],
   "source": [
    "# Main model for the MNIST dataset\n",
    "main_model = MLP(28*28, 50, 10)\n",
    "\n",
    "# Define parameters shapes and number of parameters\n",
    "param_shapes = {n: p.shape for (n, p) in main_model.named_parameters()}\n",
    "num_params = sum([p.numel() for p in main_model.parameters()])\n",
    "\n",
    "# Chunk size\n",
    "chunk_size = biggest_divisor(num_params)\n",
    "print(\"Chunk size:\", chunk_size)\n",
    "\n",
    "# Hypernetwork with sliced output    n_inp, n_hidden, n_out, chunk_size, dim_emb \n",
    "hypernetwork = Hypernetwork(n_inp=28*28, n_hidden=5, n_out=num_params, chunk_size=chunk_size, dim_emb=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the number of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in main model:  44860\n",
      "Number of parameters in hypernetwork:  8571\n",
      "Ratio:  0.1910610789121712\n"
     ]
    }
   ],
   "source": [
    "n_params_main_model = sum([p.numel() for p in main_model.parameters()])\n",
    "n_params_hypernetwork = sum([p.numel() for p in hypernetwork.parameters()])\n",
    "\n",
    "print(\"Number of parameters in main model: \", n_params_main_model)\n",
    "print(\"Number of parameters in hypernetwork: \", n_params_hypernetwork)\n",
    "\n",
    "# Ratio of parameters in hypernetwork to main model\n",
    "print(\"Ratio: \", n_params_hypernetwork / n_params_main_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The number of parameters in the Hypernetwork is now much smaller than the number of parmaeters in the main model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last step before training the model is: to define the function that reshapes the generated parameters. The reshape function can be different for each slicing technique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_generated_parameters(hn_out, param_shapes):\n",
    "    reshaped_params = {}\n",
    "    offset = 0\n",
    "    for (n, p) in param_shapes.items():\n",
    "        sliced_parameter = hn_out[0][offset:offset+p.numel()]\n",
    "        reshaped_params[n] = sliced_parameter.view(p)\n",
    "        offset += p.numel()\n",
    "\n",
    "    return reshaped_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we train the model on the MNIST dataset to see how the final performance will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "mnist_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.2860,), (0.3530,))]\n",
    ")\n",
    "train_set = datasets.MNIST(root=\"./data\", train=True,\n",
    "                           download=True, transform=mnist_transform)\n",
    "test_set = datasets.MNIST(root=\"./data\", train=False,\n",
    "                          download=True, transform=mnist_transform)\n",
    "train_loader = DataLoader(train_set, batch_size=64,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss value: 0.8588: 100%|██████████| 938/938 [00:12<00:00, 73.11it/s]\n",
      " 92%|█████████▏| 144/157 [00:00<00:00, 174.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for epoch 0: 0.7449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss value: 0.4175: 100%|██████████| 938/938 [00:14<00:00, 66.75it/s]\n",
      "100%|██████████| 157/157 [00:14<00:00, 10.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for epoch 1: 0.8642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss value: 0.4434: 100%|██████████| 938/938 [00:12<00:00, 74.59it/s]\n",
      "100%|██████████| 157/157 [00:13<00:00, 11.66it/s] \n",
      " 89%|████████▊ | 139/157 [00:00<00:00, 190.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for epoch 2: 0.8927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss value: 0.3664: 100%|██████████| 938/938 [00:13<00:00, 69.78it/s]\n",
      "100%|██████████| 157/157 [00:14<00:00, 11.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for epoch 3: 0.9088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss value: 0.2522: 100%|██████████| 938/938 [00:13<00:00, 71.67it/s]\n",
      "100%|██████████| 157/157 [00:13<00:00, 11.31it/s] \n",
      " 89%|████████▉ | 140/157 [00:00<00:00, 184.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for epoch 4: 0.9195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss value: 0.5185: 100%|██████████| 938/938 [00:13<00:00, 67.14it/s]\n",
      "100%|██████████| 157/157 [00:14<00:00, 10.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for epoch 5: 0.9278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss value: 0.1941: 100%|██████████| 938/938 [00:12<00:00, 75.08it/s]\n",
      "100%|██████████| 157/157 [00:13<00:00, 11.74it/s] \n",
      " 89%|████████▊ | 139/157 [00:00<00:00, 196.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for epoch 6: 0.9313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss value: 0.2717: 100%|██████████| 938/938 [00:13<00:00, 70.61it/s]\n",
      "100%|██████████| 157/157 [00:14<00:00, 11.14it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for epoch 7: 0.9339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss value: 0.1979: 100%|██████████| 938/938 [00:12<00:00, 75.16it/s]\n",
      "100%|██████████| 157/157 [00:13<00:00, 11.83it/s] \n",
      " 88%|████████▊ | 138/157 [00:00<00:00, 193.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for epoch 8: 0.9370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss value: 0.0741: 100%|██████████| 938/938 [00:13<00:00, 67.92it/s]\n",
      "100%|██████████| 157/157 [00:14<00:00, 10.73it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for epoch 9: 0.9416\n"
     ]
    }
   ],
   "source": [
    "# Define the optimizer and the loss function\n",
    "optimizer = torch.optim.Adam(hypernetwork.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Move the model and the hypernetwork to the device\n",
    "main_model.to(device)\n",
    "hypernetwork.to(device)\n",
    "\n",
    "# Standard PyTorch training loop\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    pbar = tqdm(train_loader)\n",
    "    for batch in pbar:\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Zero-grad optimizer for the hypernetwork\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Generate weights with the hypernetwork\n",
    "        hn_out = hypernetwork(x)\n",
    "\n",
    "        # Reshape generated weights\n",
    "        reshaped_params = reshape_generated_parameters(hn_out, param_shapes)\n",
    "\n",
    "        # Make prediction\n",
    "        pred = main_model.forward_with_params(x, reshaped_params)\n",
    "\n",
    "        # Compute loss and backpropagate\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizer step update\n",
    "        optimizer.step()\n",
    "\n",
    "        # Set progress bar description\n",
    "        pbar.set_description(f\"Loss value: {loss.item():.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Evaluate model after each epoch\n",
    "        batch_accuracies = []\n",
    "        pbar_test = tqdm(test_loader)\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            # Generate weights with the hypernetwork\n",
    "            hn_out = hypernetwork(x)\n",
    "            reshaped_params = reshape_generated_parameters(\n",
    "                hn_out, param_shapes)\n",
    "\n",
    "            # Make prediction\n",
    "            pred = main_model.forward_with_params(x, reshaped_params)\n",
    "            n_corrects = sum(pred.argmax(dim=1) == y).item()\n",
    "            acc_batch = n_corrects / len(x)\n",
    "            batch_accuracies.append(acc_batch)\n",
    "            pbar_test.update()\n",
    "\n",
    "    print(\n",
    "        f\"Average accuracy for epoch {epoch}: {sum(batch_accuracies)/len(batch_accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we got a not so bad performance for 80% less parameters in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>3. Slicing Technique 2</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align='center' style='max-width: 700px' src='images/slice_2.gif'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_inp, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(n_inp, n_hidden)\n",
    "        self.linear_2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.linear_3 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.classifier = nn.Linear(n_hidden, n_out)\n",
    "\n",
    "        self.activ = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.activ(self.linear_1(x))\n",
    "        x = self.activ(self.linear_2(x))\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward_with_params(self, x, params):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.linear(x, params[\"linear_1.weight\"], params[\"linear_1.bias\"])\n",
    "        x = F.relu(x)\n",
    "        x = F.linear(x, params[\"linear_2.weight\"], params[\"linear_2.bias\"])\n",
    "        x = F.relu(x)\n",
    "        x = F.linear(x, params[\"linear_3.weight\"], params[\"linear_3.bias\"])\n",
    "        x = F.relu(x)\n",
    "        x = F.linear(x, params[\"classifier.weight\"], params[\"classifier.bias\"])\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biggest_divisor(n):\n",
    "    if n < 50:\n",
    "        return n \n",
    "    # Find the biggest divisor of n that is smaller than the square root of n\n",
    "    for i in range(int((n)**0.5), 0, -1):\n",
    "        if n % i == 0:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperHead(nn.Module):\n",
    "    def __init__(self, n_hidden, n_out, chunk_size, dim_emb):\n",
    "        super().__init__()\n",
    "        n_chunks = n_out // chunk_size \n",
    "        self.emb = nn.Embedding(n_chunks, dim_emb)\n",
    "        self.n_chunks = n_chunks\n",
    "\n",
    "        # Initialize emb with uniform distribution\n",
    "        nn.init.uniform_(self.emb.weight, -1.0, 1.0)\n",
    "\n",
    "        # Output head linear mapping\n",
    "        self.linear_1 = nn.Linear(n_hidden + dim_emb, chunk_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Retrieve embedding for all layers\n",
    "        emb_inp = torch.arange(self.n_chunks).to(x.device)\n",
    "        emb = self.emb(emb_inp)\n",
    "\n",
    "        # Unsqueeze x in the second dimension and replicate it for n times\n",
    "        x = x.unsqueeze(1).repeat(1, self.n_chunks, 1)\n",
    "\n",
    "        # Unsqueeze emb in the first dimension and replicate it for n times\n",
    "        emb = emb.unsqueeze(0).repeat(x.shape[0], 1, 1)\n",
    "\n",
    "        # Concatenate x and emb along the last dimension\n",
    "        x = torch.cat([x, emb], dim=-1)\n",
    "\n",
    "        x = F.relu(x)\n",
    "        x = self.linear_1(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hypernetwork(nn.Module):\n",
    "    def __init__(self, n_inp, n_hidden, param_shapes, dim_emb):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(n_inp, n_hidden)\n",
    "\n",
    "        self.heads = nn.ModuleList(\n",
    "            [\n",
    "                HyperHead(n_hidden,\n",
    "                          pshape.numel(),\n",
    "                          biggest_divisor(pshape.numel()),\n",
    "                          dim_emb)\n",
    "                for pshape in param_shapes]\n",
    "        )\n",
    "        self.actv = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.actv(self.linear_1(x))\n",
    "        # loop over all heads and generate weights\n",
    "        head_outs = [self.heads[i](x) for i in range(len(self.heads))]\n",
    "        head_outs = torch.concat(head_outs, dim=1)\n",
    "\n",
    "        return head_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model = MLP(28*28, 50, 10)\n",
    "\n",
    "\n",
    "param_shapes = {n: p.shape for (n, p) in main_model.named_parameters()}\n",
    "num_params = sum([p.numel() for p in main_model.parameters()])\n",
    "hn_inp_shape = 28 * 28\n",
    "hypernetwork = Hypernetwork(hn_inp_shape, 4, list(param_shapes.values()), 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in main model:  44860\n",
      "Number of parameters in hypernetwork:  7633\n",
      "Ratio:  0.17015158270173875\n"
     ]
    }
   ],
   "source": [
    "n_params_main_model = sum([p.numel() for p in main_model.parameters()])\n",
    "n_params_hypernetwork = sum([p.numel() for p in hypernetwork.parameters()])\n",
    "\n",
    "print(\"Number of parameters in main model: \", n_params_main_model)\n",
    "print(\"Number of parameters in hypernetwork: \", n_params_hypernetwork)\n",
    "\n",
    "# Ratio of parameters in hypernetwork to main model\n",
    "print(\"Ratio: \", n_params_hypernetwork / n_params_main_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss value: 0.8883: 100%|██████████| 938/938 [00:13<00:00, 69.68it/s]\n",
      "100%|██████████| 157/157 [01:38<00:00,  1.59it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for epoch 0: 0.6665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss value: 0.8489: 100%|██████████| 938/938 [00:12<00:00, 77.18it/s]\n",
      "100%|██████████| 157/157 [00:12<00:00, 12.19it/s] \n",
      " 98%|█████████▊| 154/157 [00:00<00:00, 219.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for epoch 1: 0.7990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss value: 0.3197: 100%|██████████| 938/938 [00:13<00:00, 68.53it/s]\n",
      "100%|██████████| 157/157 [00:14<00:00, 10.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for epoch 2: 0.8273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss value: 0.9554: 100%|██████████| 938/938 [00:12<00:00, 74.49it/s]\n",
      "100%|██████████| 157/157 [00:13<00:00, 11.73it/s] \n",
      " 92%|█████████▏| 144/157 [00:00<00:00, 195.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for epoch 3: 0.8472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss value: 0.2354: 100%|██████████| 938/938 [00:13<00:00, 69.87it/s]\n",
      "100%|██████████| 157/157 [00:14<00:00, 11.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for epoch 4: 0.8634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss value: 0.5239: 100%|██████████| 938/938 [00:11<00:00, 78.43it/s]\n",
      "100%|██████████| 157/157 [00:12<00:00, 12.32it/s] \n",
      " 97%|█████████▋| 152/157 [00:00<00:00, 210.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for epoch 5: 0.8685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss value: 0.1505: 100%|██████████| 938/938 [00:13<00:00, 71.85it/s]\n",
      "100%|██████████| 157/157 [00:13<00:00, 11.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for epoch 6: 0.8883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss value: 0.3952: 100%|██████████| 938/938 [00:12<00:00, 77.82it/s]\n",
      "100%|██████████| 157/157 [00:12<00:00, 12.26it/s] \n",
      " 99%|█████████▊| 155/157 [00:00<00:00, 217.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for epoch 7: 0.8917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss value: 1.0104: 100%|██████████| 938/938 [00:13<00:00, 71.74it/s]\n",
      "100%|██████████| 157/157 [00:13<00:00, 11.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for epoch 8: 0.8902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss value: 0.6068: 100%|██████████| 938/938 [00:12<00:00, 77.54it/s]\n",
      "100%|██████████| 157/157 [00:12<00:00, 12.23it/s] \n",
      " 86%|████████▌ | 135/157 [00:00<00:00, 219.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for epoch 9: 0.8994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:18<00:00, 219.49it/s]"
     ]
    }
   ],
   "source": [
    "# Define the optimizer and the loss function\n",
    "optimizer = torch.optim.Adam(hypernetwork.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Move the model and the hypernetwork to the device\n",
    "main_model.to(device)\n",
    "hypernetwork.to(device)\n",
    "\n",
    "# Standard PyTorch training loop\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    pbar = tqdm(train_loader)\n",
    "    for batch in pbar:\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Zero-grad optimizer for the hypernetwork\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Generate weights with the hypernetwork\n",
    "        hn_out = hypernetwork(x)\n",
    "\n",
    "        # Reshape generated weights\n",
    "        reshaped_params = reshape_generated_parameters(hn_out, param_shapes)\n",
    "\n",
    "        # Make prediction\n",
    "        pred = main_model.forward_with_params(x, reshaped_params)\n",
    "\n",
    "        # Compute loss and backpropagate\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizer step update\n",
    "        optimizer.step()\n",
    "\n",
    "        # Set progress bar description\n",
    "        pbar.set_description(f\"Loss value: {loss.item():.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Evaluate model after each epoch\n",
    "        batch_accuracies = []\n",
    "        pbar_test = tqdm(test_loader)\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            # Generate weights with the hypernetwork\n",
    "            hn_out = hypernetwork(x)\n",
    "            reshaped_params = reshape_generated_parameters(\n",
    "                hn_out, param_shapes)\n",
    "\n",
    "            # Make prediction\n",
    "            pred = main_model.forward_with_params(x, reshaped_params)\n",
    "            n_corrects = sum(pred.argmax(dim=1) == y).item()\n",
    "            acc_batch = n_corrects / len(x)\n",
    "            batch_accuracies.append(acc_batch)\n",
    "            pbar_test.update()\n",
    "\n",
    "    print(\n",
    "        f\"Average accuracy for epoch {epoch}: {sum(batch_accuracies)/len(batch_accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
